{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN-task.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "jilvz1tvGJEa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Generating names with recurrent neural networks\n",
        "\n",
        "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
        "\n",
        "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
        "\n",
        "It's dangerous to go alone, take these:"
      ]
    },
    {
      "metadata": {
        "id": "3gTovVPBGnx_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "b5ca3333-86ef-48a5-ca80-ae6375f70738"
      },
      "cell_type": "code",
      "source": [
        "! shred -u setup_google_colab.py\n",
        "! wget https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py -O setup_google_colab.py\n",
        "import setup_google_colab\n",
        "setup_google_colab.setup_week5()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-20 08:03:56--  https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3792 (3.7K) [text/plain]\n",
            "Saving to: ‘setup_google_colab.py’\n",
            "\n",
            "\rsetup_google_colab.   0%[                    ]       0  --.-KB/s               \rsetup_google_colab. 100%[===================>]   3.70K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-03-20 08:03:56 (66.3 MB/s) - ‘setup_google_colab.py’ saved [3792/3792]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.696201Z",
          "start_time": "2018-08-13T20:26:38.104103Z"
        },
        "id": "ICb3Sit0GJEb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4d7536fa-ed8b-4d98-8f21-cdbfabf922ad"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "import keras_utils\n",
        "import tqdm_utils"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "eM6jzABnGJEc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load data\n",
        "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
        "\n",
        "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.701832Z",
          "start_time": "2018-08-13T20:26:42.697766Z"
        },
        "id": "y91IzINbGJEd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "start_token = \" \"  # so that the network knows that we're generating a first token\n",
        "\n",
        "# this is the token for padding,\n",
        "# we will add fake pad token at the end of names \n",
        "# to make them of equal size for further batching\n",
        "pad_token = \"#\"\n",
        "\n",
        "with open(\"names\") as f:\n",
        "    names = f.read()[:-1].split('\\n')\n",
        "    names = [start_token + name for name in names]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.707885Z",
          "start_time": "2018-08-13T20:26:42.703302Z"
        },
        "id": "xYMcG6WnGJEf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "0a0cb342-28bc-425f-e895-229326037935"
      },
      "cell_type": "code",
      "source": [
        "print('number of samples:', len(names))\n",
        "for x in names[::1000]:\n",
        "    print(x)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of samples: 7944\n",
            " Abagael\n",
            " Claresta\n",
            " Glory\n",
            " Liliane\n",
            " Prissie\n",
            " Geeta\n",
            " Giovanne\n",
            " Piggy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.857411Z",
          "start_time": "2018-08-13T20:26:42.709371Z"
        },
        "id": "b9DncWehGJEh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "ec66ceaa-f4c3-4c14-a2ff-aaff0cf44241"
      },
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = max(map(len, names))\n",
        "print(\"max length:\", MAX_LENGTH)\n",
        "\n",
        "plt.title('Sequence length distribution')\n",
        "plt.hist(list(map(len, names)), bins=25);"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max length: 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEHCAYAAACgHI2PAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "X4FHE46PGJEj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Text processing\n",
        "\n",
        "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.864592Z",
          "start_time": "2018-08-13T20:26:42.858725Z"
        },
        "id": "3WOfujBlGJEj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4f89253e-5d5d-4d0c-8026-154f8a0a523c"
      },
      "cell_type": "code",
      "source": [
        "### YOUR CODE HERE: all unique characters go here, padding included!\n",
        "tokens = ''.join(names)\n",
        "tokens = set(tokens)\n",
        "tokens.add(pad_token)\n",
        "\n",
        "tokens = list(tokens)\n",
        "n_tokens = len(tokens)\n",
        "print ('n_tokens:', n_tokens)\n",
        "\n",
        "assert 50 < n_tokens < 60"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n_tokens: 56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CGKYmgO-GJEl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Cast everything from symbols into identifiers\n",
        "\n",
        "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
        "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
        "\n",
        "To create such dictionary, let's assign `token_to_id`"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.870330Z",
          "start_time": "2018-08-13T20:26:42.866135Z"
        },
        "id": "cwbDUoXHGJEn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### YOUR CODE HERE: create a dictionary of {symbol -> its  index in tokens}\n",
        "token_to_id = {sym : idx for idx, sym in enumerate(tokens)}\n",
        "\n",
        "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.875943Z",
          "start_time": "2018-08-13T20:26:42.871834Z"
        },
        "id": "5idq1WQPGJEo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def to_matrix(names, max_len=None, pad=token_to_id[pad_token], dtype=np.int32):\n",
        "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
        "    \n",
        "    max_len = max_len or max(map(len, names))\n",
        "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
        "\n",
        "    for i in range(len(names)):\n",
        "        name_ix = list(map(token_to_id.get, names[i]))\n",
        "        names_ix[i, :len(name_ix)] = name_ix\n",
        "\n",
        "    return names_ix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.883107Z",
          "start_time": "2018-08-13T20:26:42.877186Z"
        },
        "id": "iT1zVUmhGJEq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "e3ea751e-bc71-4366-a256-310ce338895f"
      },
      "cell_type": "code",
      "source": [
        "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
        "print('\\n'.join(names[::2000]))\n",
        "print(to_matrix(names[::2000]))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Abagael\n",
            " Glory\n",
            " Prissie\n",
            " Giovanne\n",
            "[[27 11 32  2 42  2 37 53 47]\n",
            " [27 55 53  9 36 48 47 47 47]\n",
            " [27 52 36  0 30 30  0 37 47]\n",
            " [27 55  0  9 17  2 15 15 37]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Zgw6FL2WGJEt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Defining a recurrent neural network\n",
        "\n",
        "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/rnn.png?raw=1\" width=600>\n",
        "\n",
        "Since we're training a language model, there should also be:\n",
        "* An embedding layer that converts character id x_t to a vector.\n",
        "* An output layer that predicts probabilities of next phoneme based on h_t+1"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.039419Z",
          "start_time": "2018-08-13T20:26:42.884581Z"
        },
        "id": "dy2N-I3IGJEt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# remember to reset your session if you change your graph!\n",
        "s = keras_utils.reset_tf_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.044903Z",
          "start_time": "2018-08-13T20:26:44.041084Z"
        },
        "id": "NtWOR0fgGJEv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.layers import concatenate, Dense, Embedding\n",
        "\n",
        "rnn_num_units = 64  # size of hidden state\n",
        "embedding_size = 16  # for characters\n",
        "\n",
        "# Let's create layers for our recurrent network\n",
        "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
        "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
        "\n",
        "# an embedding layer that converts character ids into embeddings\n",
        "embed_x = Embedding(n_tokens, embedding_size)\n",
        "\n",
        "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
        "### YOUR CODE HERE\n",
        "get_h_next = Dense(rnn_num_units, activation = 'elu')\n",
        "\n",
        "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
        "### YOUR CODE HERE \n",
        "get_probas = Dense(n_tokens, activation = 'softmax')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8jLF_DlnGJEy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We will generate names character by character starting with `start_token`:\n",
        "\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/char-nn.png?raw=1\" width=600>"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.053212Z",
          "start_time": "2018-08-13T20:26:44.048389Z"
        },
        "id": "hx1NvdTlGJEy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def rnn_one_step(x_t, h_t):\n",
        "    \"\"\"\n",
        "    Recurrent neural network step that produces \n",
        "    probabilities for next token x_t+1 and next state h_t+1\n",
        "    given current input x_t and previous state h_t.\n",
        "    We'll call this method repeatedly to produce the whole sequence.\n",
        "    \n",
        "    You're supposed to \"apply\" above layers to produce new tensors.\n",
        "    Follow inline instructions to complete the function.\n",
        "    \"\"\"\n",
        "    # convert character id into embedding\n",
        "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
        "    \n",
        "    # concatenate x_t embedding and previous h_t state\n",
        "    ### YOUR CODE HERE\n",
        "    x_and_h = tf.concat([x_t_emb, h_t], 1)\n",
        "    \n",
        "    # compute next state given x_and_h\n",
        "    ### YOUR CODE HERE\n",
        "    h_next = get_h_next(x_and_h)\n",
        "    \n",
        "    # get probabilities for language model P(x_next|h_next)\n",
        "    ### YOUR CODE HERE\n",
        "    output_probas = get_probas(h_next)\n",
        "    \n",
        "    return output_probas, h_next"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "axAxuHVxGJE0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: loop\n",
        "\n",
        "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
        "\n",
        "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.342948Z",
          "start_time": "2018-08-13T20:26:44.056136Z"
        },
        "id": "V9VxcpZlGJE0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b8b55262-f7ea-4781-9768-d3d4b1a7b08d"
      },
      "cell_type": "code",
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
        "batch_size = tf.shape(input_sequence)[0]\n",
        "\n",
        "predicted_probas = []\n",
        "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
        "\n",
        "for t in range(MAX_LENGTH):\n",
        "    x_t = input_sequence[:, t]  # column t\n",
        "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
        "    \n",
        "    h_prev = h_next\n",
        "    predicted_probas.append(probas_next)\n",
        "    \n",
        "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
        "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
        "\n",
        "# next to last token prediction is not needed\n",
        "predicted_probas = predicted_probas[:, :-1, :]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IZZW_kgtGJE1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: loss and gradients\n",
        "\n",
        "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
        "\n",
        "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
        "\n",
        "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.354310Z",
          "start_time": "2018-08-13T20:26:44.344648Z"
        },
        "id": "sD93DncqGJE2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# flatten predictions to [batch*time, n_tokens]\n",
        "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
        "\n",
        "# flatten answers (next tokens) and one-hot encode them\n",
        "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zm_iKibPGJE4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
        "\n",
        "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
        "\n",
        "For simplicity you can ignore this comment, it's up to you."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:45.076642Z",
          "start_time": "2018-08-13T20:26:44.355594Z"
        },
        "id": "QqqsGGoIGJE4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
        "# Mind that predictions are probabilities and NOT logits!\n",
        "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
        "### YOUR CODE HERE\n",
        "mult = answers_matrix * tf.log(predictions_matrix)\n",
        "loss = -tf.reduce_mean(mult)\n",
        "\n",
        "optimize = tf.train.AdamOptimizer().minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5-Hu5dv9GJE6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: training"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.322187Z",
          "start_time": "2018-08-13T20:26:45.078296Z"
        },
        "id": "Kxh2rXtLGJE6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "3b8856e2-a89f-4d65-e8fa-3236260e41bb"
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "batch_size = 32\n",
        "history = []\n",
        "\n",
        "for i in range(1000):\n",
        "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
        "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
        "    \n",
        "    history.append(loss_i)\n",
        "    \n",
        "    if (i + 1) % 100 == 0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history, label='loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXQghLEiCuxBCWND/B6721HJQ9povAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "GWPnuypyGJE8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: sampling\n",
        "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.341196Z",
          "start_time": "2018-08-13T20:26:55.323787Z"
        },
        "id": "1W5WRmp1GJE9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_t = tf.placeholder(tf.int32, (1,))\n",
        "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
        "\n",
        "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
        "# We reuse all parameters thanks to functional API usage.\n",
        "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
        "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
        "next_probs, next_h = rnn_one_step(x_t, h_t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.346422Z",
          "start_time": "2018-08-13T20:26:55.342659Z"
        },
        "id": "NR6Ae6jCGJE-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
        "    '''\n",
        "    This function generates text given a `seed_phrase` as a seed.\n",
        "    Remember to include start_token in seed phrase!\n",
        "    Parameter `max_length` is used to set the number of characters in prediction.\n",
        "    '''\n",
        "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
        "    s.run(tf.assign(h_t, h_t.initial_value))\n",
        "    \n",
        "    # feed the seed phrase, if any\n",
        "    for ix in x_sequence[:-1]:\n",
        "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
        "    \n",
        "    # start generating\n",
        "    for _ in range(max_length-len(seed_phrase)):\n",
        "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
        "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
        "        \n",
        "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:58.458115Z",
          "start_time": "2018-08-13T20:26:55.347900Z"
        },
        "id": "q5BT1X0BGJFA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "87b7c622-bf44-45de-b85b-f70442dd82a9"
      },
      "cell_type": "code",
      "source": [
        "# without prefix\n",
        "for _ in range(10):\n",
        "    print(generate_sample())"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Ine\n",
            " Diosnen\n",
            " Mecew\n",
            " Dolorh\n",
            " Wytre\n",
            " Herry\n",
            " Olan\n",
            " Blonm\n",
            " Innlva\n",
            " Jeyn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:01.986726Z",
          "start_time": "2018-08-13T20:26:58.459810Z"
        },
        "id": "C30T1oEOGJFC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "a9bf4d84-70b4-42fb-f5c5-0fa68d72a5fb"
      },
      "cell_type": "code",
      "source": [
        "# with prefix conditioning\n",
        "for _ in range(10):\n",
        "    print(generate_sample(' Trump'))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Trumpalhod\n",
            " Trumpyni\n",
            " Trump\n",
            " Trumpenhe\n",
            " Trump\n",
            " Trumpory\n",
            " Trumpa\n",
            " Trumpa\n",
            " Trump\n",
            " Trumpida\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GoZbncXoGJFE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Submit to Coursera"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:02.004926Z",
          "start_time": "2018-08-13T20:40:02.000821Z"
        },
        "id": "lN1A33AvGJFE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# token expires every 30 min\n",
        "COURSERA_TOKEN = \n",
        "COURSERA_EMAIL = "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:18.923357Z",
          "start_time": "2018-08-13T20:40:03.549343Z"
        },
        "id": "YrcswV3LGJFH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c47445d3-e8f2-434b-a080-99c6c8f95358"
      },
      "cell_type": "code",
      "source": [
        "from submit import submit_char_rnn\n",
        "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
        "submission = (history, samples)\n",
        "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************\n",
            "\n",
            "Submitted to Coursera platform. See results on assignment page!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "84XJSsVyGJFI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Try it out!\n",
        "\n",
        "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
        "\n",
        "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
        "\n",
        "* Novels/poems/songs of your favorite author\n",
        "* News titles/clickbait titles\n",
        "* Source code of Linux or Tensorflow\n",
        "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
        "* Melody in notes/chords format\n",
        "* IKEA catalog titles\n",
        "* Pokemon names\n",
        "* Cards from Magic, the Gathering / Hearthstone\n",
        "\n",
        "If you're willing to give it a try, here's what you wanna look at:\n",
        "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
        "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
        "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
        "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
        "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
        "\n",
        "__Good hunting!__"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "HifDBWXcGJFJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Bonus level: dynamic RNNs\n",
        "\n",
        "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
        "\n",
        "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
        "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
        "\n",
        "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.975354Z",
          "start_time": "2018-08-13T20:27:12.737529Z"
        },
        "id": "5IiLQAJqGJFJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "d05d4d08-6412-4a5b-c08b-864b70402759"
      },
      "cell_type": "code",
      "source": [
        "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
        "    def call(self, input, state):\n",
        "        # from docs:\n",
        "        # Returns:\n",
        "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
        "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
        "        return rnn_one_step(input[:, 0], state)\n",
        "    \n",
        "    @property\n",
        "    def output_size(self):\n",
        "        return n_tokens\n",
        "    \n",
        "cell = CustomRNN(rnn_num_units)\n",
        "\n",
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "    \n",
        "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
        "\n",
        "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
        "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-33-5f3812e903bf>:13: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-33-5f3812e903bf>:17: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "LSTM outputs for each step [batch,time,n_tokens]:\n",
            "(10, 50, 56)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8BRf4ZR5GJFK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
        "\n",
        "You can also use any pre-implemented RNN cell:"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.981697Z",
          "start_time": "2018-08-13T20:27:12.977590Z"
        },
        "id": "RvMX4y_3GJFL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0489bb1d-f0b4-47fb-8c46-e428edd8869d"
      },
      "cell_type": "code",
      "source": [
        "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
        "    if obj.endswith('Cell'):\n",
        "        print(obj, end=\"\\t\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BasicLSTMCell\tBasicRNNCell\tGRUCell\tLSTMCell\tMultiRNNCell\tRNNCell\tBasicLSTMCell\tBasicRNNCell\tBidirectionalGridLSTMCell\tConv1DLSTMCell\tConv2DLSTMCell\tConv3DLSTMCell\tConvLSTMCell\tCoupledInputForgetGateLSTMCell\tFusedRNNCell\tGLSTMCell\tGRUBlockCell\tGRUCell\tGridLSTMCell\tIndRNNCell\tIndyGRUCell\tIndyLSTMCell\tIntersectionRNNCell\tLSTMBlockCell\tLSTMBlockFusedCell\tLSTMCell\tLayerNormBasicLSTMCell\tLayerRNNCell\tMultiRNNCell\tNASCell\tPhasedLSTMCell\tRNNCell\tSRUCell\tTimeFreqLSTMCell\tUGRNNCell\t"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:13.168207Z",
          "start_time": "2018-08-13T20:27:12.986884Z"
        },
        "id": "eNEkxK9qGJFN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "f4dbc68d-44a2-4c65-e298-19be18ef705b"
      },
      "cell_type": "code",
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "\n",
        "inputs_embedded = embed_x(input_sequence)\n",
        "\n",
        "# standard cell returns hidden state as output!\n",
        "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
        "\n",
        "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
        "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-35-62766a2145fb>:6: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "LSTM hidden state for each step [batch,time,rnn_num_units]:\n",
            "(10, 50, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_dmYsxIrOeNY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}